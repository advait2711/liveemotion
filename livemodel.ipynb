{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fer2013.csv')\n",
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 35\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y= to_categorical(train_y, num_classes=num_labels)\n",
    "test_y= to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##designing the cnn\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 46, 46, 64)        640       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 44, 44, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 22, 22, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 20, 20, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 18, 18, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 9, 9, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 2, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1914951 (7.30 MB)\n",
      "Trainable params: 1914951 (7.30 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "WARNING:tensorflow:From C:\\Users\\advait\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\advait\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "449/449 [==============================] - 82s 179ms/step - loss: 1.7354 - accuracy: 0.2907 - val_loss: 1.5751 - val_accuracy: 0.3795\n",
      "Epoch 2/35\n",
      "449/449 [==============================] - 94s 209ms/step - loss: 1.5167 - accuracy: 0.4049 - val_loss: 1.3893 - val_accuracy: 0.4622\n",
      "Epoch 3/35\n",
      "449/449 [==============================] - 113s 252ms/step - loss: 1.4016 - accuracy: 0.4597 - val_loss: 1.3822 - val_accuracy: 0.4714\n",
      "Epoch 4/35\n",
      "449/449 [==============================] - 94s 210ms/step - loss: 1.3415 - accuracy: 0.4810 - val_loss: 1.3181 - val_accuracy: 0.4896\n",
      "Epoch 5/35\n",
      "449/449 [==============================] - 93s 207ms/step - loss: 1.2925 - accuracy: 0.5027 - val_loss: 1.2296 - val_accuracy: 0.5252\n",
      "Epoch 6/35\n",
      "449/449 [==============================] - 99s 220ms/step - loss: 1.2559 - accuracy: 0.5200 - val_loss: 1.2124 - val_accuracy: 0.5322\n",
      "Epoch 7/35\n",
      "449/449 [==============================] - 104s 233ms/step - loss: 1.2211 - accuracy: 0.5332 - val_loss: 1.2135 - val_accuracy: 0.5467\n",
      "Epoch 8/35\n",
      "449/449 [==============================] - 85s 189ms/step - loss: 1.1978 - accuracy: 0.5402 - val_loss: 1.2159 - val_accuracy: 0.5419\n",
      "Epoch 9/35\n",
      "449/449 [==============================] - 91s 203ms/step - loss: 1.1747 - accuracy: 0.5524 - val_loss: 1.1726 - val_accuracy: 0.5542\n",
      "Epoch 10/35\n",
      "449/449 [==============================] - 85s 190ms/step - loss: 1.1523 - accuracy: 0.5584 - val_loss: 1.1718 - val_accuracy: 0.5492\n",
      "Epoch 11/35\n",
      "449/449 [==============================] - 92s 205ms/step - loss: 1.1266 - accuracy: 0.5693 - val_loss: 1.1707 - val_accuracy: 0.5528\n",
      "Epoch 12/35\n",
      "449/449 [==============================] - 97s 216ms/step - loss: 1.1149 - accuracy: 0.5750 - val_loss: 1.1892 - val_accuracy: 0.5442\n",
      "Epoch 13/35\n",
      "449/449 [==============================] - 86s 192ms/step - loss: 1.1001 - accuracy: 0.5798 - val_loss: 1.1544 - val_accuracy: 0.5639\n",
      "Epoch 14/35\n",
      "449/449 [==============================] - 87s 193ms/step - loss: 1.0724 - accuracy: 0.5920 - val_loss: 1.1743 - val_accuracy: 0.5645\n",
      "Epoch 15/35\n",
      "449/449 [==============================] - 95s 212ms/step - loss: 1.0673 - accuracy: 0.5886 - val_loss: 1.1695 - val_accuracy: 0.5598\n",
      "Epoch 16/35\n",
      "449/449 [==============================] - 115s 256ms/step - loss: 1.0417 - accuracy: 0.6042 - val_loss: 1.1699 - val_accuracy: 0.5528\n",
      "Epoch 17/35\n",
      "449/449 [==============================] - 91s 203ms/step - loss: 1.0242 - accuracy: 0.6120 - val_loss: 1.1722 - val_accuracy: 0.5765\n",
      "Epoch 18/35\n",
      "449/449 [==============================] - 92s 205ms/step - loss: 1.0125 - accuracy: 0.6097 - val_loss: 1.1832 - val_accuracy: 0.5690\n",
      "Epoch 19/35\n",
      "449/449 [==============================] - 96s 213ms/step - loss: 0.9958 - accuracy: 0.6235 - val_loss: 1.1605 - val_accuracy: 0.5695\n",
      "Epoch 20/35\n",
      "449/449 [==============================] - 96s 213ms/step - loss: 0.9825 - accuracy: 0.6250 - val_loss: 1.1817 - val_accuracy: 0.5645\n",
      "Epoch 21/35\n",
      "449/449 [==============================] - 86s 192ms/step - loss: 0.9638 - accuracy: 0.6323 - val_loss: 1.1967 - val_accuracy: 0.5612\n",
      "Epoch 22/35\n",
      "449/449 [==============================] - 83s 186ms/step - loss: 0.9537 - accuracy: 0.6358 - val_loss: 1.1810 - val_accuracy: 0.5665\n",
      "Epoch 23/35\n",
      "449/449 [==============================] - 83s 185ms/step - loss: 0.9382 - accuracy: 0.6429 - val_loss: 1.1862 - val_accuracy: 0.5665\n",
      "Epoch 24/35\n",
      "449/449 [==============================] - 672s 1s/step - loss: 0.9182 - accuracy: 0.6502 - val_loss: 1.2141 - val_accuracy: 0.5690\n",
      "Epoch 25/35\n",
      "449/449 [==============================] - 76s 168ms/step - loss: 0.9097 - accuracy: 0.6541 - val_loss: 1.1933 - val_accuracy: 0.5667\n",
      "Epoch 26/35\n",
      "449/449 [==============================] - 77s 171ms/step - loss: 0.8961 - accuracy: 0.6581 - val_loss: 1.2254 - val_accuracy: 0.5564\n",
      "Epoch 27/35\n",
      "449/449 [==============================] - 77s 172ms/step - loss: 0.8795 - accuracy: 0.6680 - val_loss: 1.2103 - val_accuracy: 0.5639\n",
      "Epoch 28/35\n",
      "449/449 [==============================] - 89s 198ms/step - loss: 0.8616 - accuracy: 0.6744 - val_loss: 1.2135 - val_accuracy: 0.5756\n",
      "Epoch 29/35\n",
      "449/449 [==============================] - 82s 184ms/step - loss: 0.8556 - accuracy: 0.6757 - val_loss: 1.2197 - val_accuracy: 0.5575\n",
      "Epoch 30/35\n",
      "449/449 [==============================] - 99s 221ms/step - loss: 0.8345 - accuracy: 0.6850 - val_loss: 1.2134 - val_accuracy: 0.5673\n",
      "Epoch 31/35\n",
      "449/449 [==============================] - 106s 235ms/step - loss: 0.8236 - accuracy: 0.6894 - val_loss: 1.2253 - val_accuracy: 0.5762\n",
      "Epoch 32/35\n",
      "449/449 [==============================] - 87s 193ms/step - loss: 0.8085 - accuracy: 0.6945 - val_loss: 1.2288 - val_accuracy: 0.5695\n",
      "Epoch 33/35\n",
      "449/449 [==============================] - 81s 179ms/step - loss: 0.7916 - accuracy: 0.6995 - val_loss: 1.2363 - val_accuracy: 0.5715\n",
      "Epoch 34/35\n",
      "449/449 [==============================] - 81s 180ms/step - loss: 0.7895 - accuracy: 0.7016 - val_loss: 1.2755 - val_accuracy: 0.5670\n",
      "Epoch 35/35\n",
      "449/449 [==============================] - 84s 187ms/step - loss: 0.7768 - accuracy: 0.7058 - val_loss: 1.3042 - val_accuracy: 0.5765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1faa5c3b550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the  model to\n",
    "fer_json = model.to_json()\n",
    "with open(\"livemodel.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"livemodel.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
